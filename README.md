# SignTech-SignLanguageDetection
This repository contains 3 ipynb files
1) create_data_gesture: It uses OpenCV to help develop your own dataset
2) trainCNN: It uses keras model to train your dataset to the corresponding classes.
3) model_for_gesture: It taken in real time frames and predict the sign language to English alphabet.

The two h5 files, contour_sign_detection and edge_sign_detection, are the trained models (which are the two different techniques for storing the dataset).

gesture1 is the dataset containing testing and training data for contours and edges respectively. The dataset has around 11000 images for contours and edges.
